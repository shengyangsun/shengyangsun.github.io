# üìù Publications 
## üèπ Selected Projects


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2025</div><img src='images/TGMVAD.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Enhancing Weakly Supervised Multimodal Video Anomaly Detection through Text Guidance \\
**Shengyang Sun**, Jiashen Hua, Junyi Feng, Xiaojin Gong

[**Project**](https://shengyangsun.github.io/TGMVAD/)

- TGMVAD is the first work to employ in-context learning (ICL) to the task of weakly-supervised multimodal video anomaly detection for the purpose of augmenting text samples.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT 2025</div><img src='images/DSM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Delving Into Instance Modeling for Weakly Supervised Video Anomaly Detection](https://ieeexplore.ieee.org/abstract/document/10908237) \\
**Shengyang Sun**, Jiashen Hua, Junyi Feng, Dongxu Wei, Baisheng Lai, Xiaojin Gong

- This is the first work to our knowledge that deliberately explores the issue of anomaly contamination and dilution along the temporal dimension, which is overlooked by prior MIL-based weakly-supervised video anomaly detection works.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/TDSD.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Hierarchical semantic contrast for scene-aware video anomaly detection](http://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Hierarchical_Semantic_Contrast_for_Scene-Aware_Video_Anomaly_Detection_CVPR_2023_paper.pdf) \\
**Shengyang Sun**, Xiaojin Gong

[**Code**](https://github.com/shengyangsun/HSC_VAD)

- We build a scene-aware reconstruction framework composed of scene-aware feature encoders and objectcentric feature decoders for anomaly detection.
- We propose hierarchical semantic contrastive learning to regularize the encoded features in the latent spaces, making normal features more compact within the same semantic classes and separable between different classes.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2024</div><img src='images/TDSD.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TDSD: Text-Driven Scene-Decoupled Weakly Supervised Video Anomaly Detection](https://openreview.net/pdf?id=TAVtkpjS9P) \\
**Shengyang Sun**, Jiashen Hua, Junyi Feng, Dongxu Wei, Baisheng Lai, Xiaojin Gong

- This is the first work to address scene-dependent video anomaly detection under a weakly supervised setting.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICME 2024</div><img src='images/MSBT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-scale Bottleneck Transformer for Weakly Supervised Multimodal Violence Detection](https://arxiv.org/pdf/2405.05130) \\
**Shengyang Sun**, Xiaojin Gong

[**Code**](https://github.com/shengyangsun/MSBT)

- We propose a multi-scale bottleneck transformer (MSBT)-based fusion module. It leverages a reduced number of bottleneck tokens to transmit gradually condensed information from one modality to another and a bottleneck token-based weighting scheme to weight the fused features, effectively addressing the information redundancy and modality imbalance problems.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICME 2023</div><img src='images/LSTC.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Long-Short Temporal Co-Teaching for Weakly Supervised Video Anomaly Detection](https://arxiv.org/pdf/2303.18044) \\
**Shengyang Sun**, Xiaojin Gong

[**Code**](https://github.com/shengyangsun/LSTC_VAD)

- We employ a co-teaching strategy to train short- and long-term networks alternatively and iteratively. The two networks can explicitly learn from abnormal events with varying durations.
</div>
</div>
